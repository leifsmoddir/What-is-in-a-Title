{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_bi = pd.read_csv('../data/shakespearean_bigrams_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_len</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205373</th>\n",
       "      <td>thou note</td>\n",
       "      <td>['thou', 'note']</td>\n",
       "      <td>['NN', 'NN']</td>\n",
       "      <td>['NN', 'NN']</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192052</th>\n",
       "      <td>the blackest</td>\n",
       "      <td>['the', 'blackest']</td>\n",
       "      <td>['DT', 'JJS']</td>\n",
       "      <td>['DT', 'JJS']</td>\n",
       "      <td>2</td>\n",
       "      <td>DT</td>\n",
       "      <td>JJS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114350</th>\n",
       "      <td>look they</td>\n",
       "      <td>['look', 'they']</td>\n",
       "      <td>['NN', 'PRP']</td>\n",
       "      <td>['NN', 'PRP']</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182886</th>\n",
       "      <td>strange insurrections</td>\n",
       "      <td>['strange', 'insurrections']</td>\n",
       "      <td>['JJ', 'NNS']</td>\n",
       "      <td>['JJ', 'NNS']</td>\n",
       "      <td>2</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152805</th>\n",
       "      <td>pluck 'd</td>\n",
       "      <td>['pluck', \"'d\"]</td>\n",
       "      <td>['NN', 'MD']</td>\n",
       "      <td>['NN', 'MD']</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title               title_tokenized        pos_tag  \\\n",
       "205373              thou note              ['thou', 'note']   ['NN', 'NN']   \n",
       "192052           the blackest           ['the', 'blackest']  ['DT', 'JJS']   \n",
       "114350              look they              ['look', 'they']  ['NN', 'PRP']   \n",
       "182886  strange insurrections  ['strange', 'insurrections']  ['JJ', 'NNS']   \n",
       "152805               pluck 'd               ['pluck', \"'d\"]   ['NN', 'MD']   \n",
       "\n",
       "                  pos  pos_len pos1 pos2  \n",
       "205373   ['NN', 'NN']        2   NN   NN  \n",
       "192052  ['DT', 'JJS']        2   DT  JJS  \n",
       "114350  ['NN', 'PRP']        2   NN  PRP  \n",
       "182886  ['JJ', 'NNS']        2   JJ  NNS  \n",
       "152805   ['NN', 'MD']        2   NN   MD  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake_bi.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_bi = shake_bi.drop(columns=['title_tokenized', 'pos_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_len</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>title_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198858</th>\n",
       "      <td>their tender</td>\n",
       "      <td>['PRP$', 'NN']</td>\n",
       "      <td>2</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>NN</td>\n",
       "      <td>[their, tender]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101585</th>\n",
       "      <td>instigated by</td>\n",
       "      <td>['VBN', 'IN']</td>\n",
       "      <td>2</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>[instigated, by]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30054</th>\n",
       "      <td>bought mine</td>\n",
       "      <td>['NN', 'NN']</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>[bought, mine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18986</th>\n",
       "      <td>as they</td>\n",
       "      <td>['IN', 'PRP']</td>\n",
       "      <td>2</td>\n",
       "      <td>IN</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[as, they]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144203</th>\n",
       "      <td>or from</td>\n",
       "      <td>['CC', 'IN']</td>\n",
       "      <td>2</td>\n",
       "      <td>CC</td>\n",
       "      <td>IN</td>\n",
       "      <td>[or, from]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                title             pos  pos_len  pos1 pos2       title_token\n",
       "198858   their tender  ['PRP$', 'NN']        2  PRP$   NN   [their, tender]\n",
       "101585  instigated by   ['VBN', 'IN']        2   VBN   IN  [instigated, by]\n",
       "30054     bought mine    ['NN', 'NN']        2    NN   NN    [bought, mine]\n",
       "18986         as they   ['IN', 'PRP']        2    IN  PRP        [as, they]\n",
       "144203        or from    ['CC', 'IN']        2    CC   IN        [or, from]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd = TreebankWordTokenizer()\n",
    "shake_bi['title_token'] = shake_bi['title'].apply(lambda x: twd.tokenize(x))\n",
    "shake_bi.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous work has demonstrated that words with a period at the end (such as `soldier.`) will not have an accompanying word vector, which would result in the loss of thousands of entries. The below code will remove the period at the end of such words, but will retain other punctuation and single event periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = shake_bi.title_token.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "second = []\n",
    "\n",
    "for title in titles:\n",
    "    first.append(title[0])\n",
    "    second.append(title[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_first = []\n",
    "\n",
    "for word in first:\n",
    "    if len(word) > 1 and word.endswith('.'):\n",
    "        new_first.append(word.rstrip(word[-1]))\n",
    "    else:\n",
    "        new_first.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_second = []\n",
    "\n",
    "for word in second:\n",
    "    if len(word) > 1 and word.endswith('.'):\n",
    "        new_second.append(word.rstrip(word[-1]))\n",
    "    else:\n",
    "        new_second.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_clean = list(list(x) for x in zip(new_first, new_second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['soldier', 'with'],\n",
       " ['soldier', 'you'],\n",
       " ['soldier-like', 'phrase'],\n",
       " ['soldier', 'and'],\n",
       " ['soldier', 'let']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_clean[177240:177245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_len</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>title_token</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210605</th>\n",
       "      <td>to example</td>\n",
       "      <td>['TO', 'NN']</td>\n",
       "      <td>2</td>\n",
       "      <td>TO</td>\n",
       "      <td>NN</td>\n",
       "      <td>[to, example]</td>\n",
       "      <td>[to, example]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82764</th>\n",
       "      <td>hate '</td>\n",
       "      <td>['NN', '\"\"']</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>[hate, ']</td>\n",
       "      <td>[hate, ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93104</th>\n",
       "      <td>hit the</td>\n",
       "      <td>['VB', 'DT']</td>\n",
       "      <td>2</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>[hit, the]</td>\n",
       "      <td>[hit, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61280</th>\n",
       "      <td>every coast</td>\n",
       "      <td>['DT', 'NN']</td>\n",
       "      <td>2</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "      <td>[every, coast]</td>\n",
       "      <td>[every, coast]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105881</th>\n",
       "      <td>jove and</td>\n",
       "      <td>['NN', 'CC']</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>[jove, and]</td>\n",
       "      <td>[jove, and]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title           pos  pos_len pos1 pos2     title_token  \\\n",
       "210605   to example  ['TO', 'NN']        2   TO   NN   [to, example]   \n",
       "82764        hate '  ['NN', '\"\"']        2   NN   \"\"       [hate, ']   \n",
       "93104       hit the  ['VB', 'DT']        2   VB   DT      [hit, the]   \n",
       "61280   every coast  ['DT', 'NN']        2   DT   NN  [every, coast]   \n",
       "105881     jove and  ['NN', 'CC']        2   NN   CC     [jove, and]   \n",
       "\n",
       "           title_clean  \n",
       "210605   [to, example]  \n",
       "82764        [hate, ']  \n",
       "93104       [hit, the]  \n",
       "61280   [every, coast]  \n",
       "105881     [jove, and]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake_bi['title_clean'] = title_clean\n",
    "shake_bi.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to replace every word in each bigram with the learned word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.models.KeyedVectors.load(\"shake_w2v.wordsvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26304"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set(wv.index2word)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vect = [np.array([wv[i] for i in ls if i in words])\n",
    "                                for ls in shake_bi['title_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bigrams with no word matches form title_clean 67\n"
     ]
    }
   ],
   "source": [
    "loss_title_clean = []\n",
    "\n",
    "for i,v in enumerate(bigram_vect):\n",
    "    if len(v) != 2:\n",
    "        loss_title_clean.append(i)\n",
    "#         print(shake_bi['title_clean'][i])\n",
    "#         print('Vector len:', len(v), 'Index:', i)\n",
    "\n",
    "print('Number of bigrams with no word matches form title_clean', len(loss_title_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vect2 = [np.array([wv[i] for i in ls if i in words])\n",
    "                                for ls in shake_bi['title_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bigrams with no word matches form title_token 5970\n"
     ]
    }
   ],
   "source": [
    "loss_title_token = []\n",
    "\n",
    "for i,v in enumerate(bigram_vect2):\n",
    "    if len(v) != 2:\n",
    "        loss_title_token.append(i)\n",
    "\n",
    "print('Number of bigrams with no word matches form title_token', len(loss_title_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the above coding, I think I would rather lose 5,970 titles. Now that it is morning, and I am thinking *clearly*, I would not want most of those titles anyway because they are at the end of a sentence. I think it was my original belief, that genism took sentence ends into consideration. Reversing course below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_len</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>title_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120676</th>\n",
       "      <td>me something</td>\n",
       "      <td>['PRP', 'NN']</td>\n",
       "      <td>2</td>\n",
       "      <td>PRP</td>\n",
       "      <td>NN</td>\n",
       "      <td>[me, something]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title            pos  pos_len pos1 pos2      title_token\n",
       "120676  me something  ['PRP', 'NN']        2  PRP   NN  [me, something]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake_bi.drop(columns=['title_clean'], inplace=True)\n",
    "shake_bi.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_len</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>title_token</th>\n",
       "      <th>word_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237925</th>\n",
       "      <td>ye done</td>\n",
       "      <td>['NN', 'VBN']</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>[ye, done]</td>\n",
       "      <td>[[0.38721955, -0.6298508, -0.64152753, 0.5480759, -0.27110818, -0.39844513, -0.043123763, -0.7947163, 0.72984946, -0.16564111, -0.33992615, -0.92562103, 0.14775954, -0.36516213, -0.5071994, 0.099314995, -0.22760622, 0.3127083, 0.07279155, -0.5925049, 0.19713917, -0.09201206, 0.11940089, -0.17175232, 0.54297876, 0.31815404, -0.19652726, 0.5672226, 0.78805965, 0.24863446, 0.85366786, 0.31839156, -0.29994288, 0.48651826, -0.16115738, 0.30141068, 0.8820832, -0.791511, -0.13478667, -0.34277233, 0.43665951, -0.39968136, 0.1799807, -0.36762482, 0.3285105, -0.0061254804, -0.088755235, 0.29515928, -0.016218198, 0.013438691, 0.13234694, 0.072043456, -0.117082514, 0.18616527, -0.49476078, -0.15034261, 0.34449473, -0.7079535, -0.0849729, 0.7924161, 0.53180283, 0.022599643, -0.73220396, -0.3911725, 0.48320225, 0.20673294, 0.7856577, 0.011493572, 0.43976203, -0.32445842, 0.08919123, -0.6732706, 0.003777869, 0.56608033, 0.9314576, -0.13060005, -0.088135466, -0.108308144, 0.27884117, -0.46055293, 0.07342696, 0.0559225, 0.69816613, 0.4011239, -0.028544694, 0.08064641, 0.026036564, -0.19206068, -0.41460633, -0.4037335, 0.2626454, -0.12135888, 0.3745098, -0.13898301, 0.054465998, -0.116109446, 0.11705433, 0.4324808, -0.12951922, 0.22345495, ...], [-0.07660817, -0.46201295, -0.5043615, -0.37414637, -0.31470814, -0.8197248, -0.44553378, -0.5021222, -0.2418622, -0.031998783, -0.23411427, -0.55792576, 0.64886415, -0.70458436, -0.76247084, 0.19106038, 0.41632313, 0.26451474, -0.6341871, -0.67780197, 0.07453282, -0.50505286, -0.2803194, -0.08616192, 0.52132565, 0.36279613, 0.06505542, 0.8476284, 0.5180436, -0.052286968, 1.2920185, 0.014844066, 0.4599209, 0.7517877, -0.2820122, -0.13168254, 0.8589992, -0.9272397, -0.062209684, 0.22712871, -0.05800619, -0.94080347, 1.1490519, -0.070918664, 0.4371037, 0.16446914, -0.8361203, 0.871916, 0.2964518, -0.35617283, -0.12215503, 0.37325692, -0.031303022, -0.11569968, -0.93556637, -0.35087806, 0.4073037, -0.37156284, 0.17356054, -0.02665485, 0.7202497, 1.1636028, -1.4689933, 0.16169229, 0.5691571, 0.39378658, 1.2258487, -0.65096074, -0.007456261, -0.08383923, 0.19063438, -0.20051263, -0.54743105, -0.023379356, 0.9503865, -0.4447622, 0.17243233, 0.30253276, 0.042590097, 0.07329144, 0.17095493, 0.3200955, -0.2536034, 0.06708895, -0.5525636, -0.22286516, -0.2790356, -0.37580344, 0.0032717872, -0.3346582, -0.7029885, 0.49254662, 0.25746125, 0.0010136539, -0.70784163, 0.6414307, -0.046651535, 0.5646374, -1.0406041, -0.37364417, ...]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title            pos  pos_len pos1 pos2 title_token  \\\n",
       "237925  ye done  ['NN', 'VBN']        2   NN  VBN  [ye, done]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      word_vec  \n",
       "237925  [[0.38721955, -0.6298508, -0.64152753, 0.5480759, -0.27110818, -0.39844513, -0.043123763, -0.7947163, 0.72984946, -0.16564111, -0.33992615, -0.92562103, 0.14775954, -0.36516213, -0.5071994, 0.099314995, -0.22760622, 0.3127083, 0.07279155, -0.5925049, 0.19713917, -0.09201206, 0.11940089, -0.17175232, 0.54297876, 0.31815404, -0.19652726, 0.5672226, 0.78805965, 0.24863446, 0.85366786, 0.31839156, -0.29994288, 0.48651826, -0.16115738, 0.30141068, 0.8820832, -0.791511, -0.13478667, -0.34277233, 0.43665951, -0.39968136, 0.1799807, -0.36762482, 0.3285105, -0.0061254804, -0.088755235, 0.29515928, -0.016218198, 0.013438691, 0.13234694, 0.072043456, -0.117082514, 0.18616527, -0.49476078, -0.15034261, 0.34449473, -0.7079535, -0.0849729, 0.7924161, 0.53180283, 0.022599643, -0.73220396, -0.3911725, 0.48320225, 0.20673294, 0.7856577, 0.011493572, 0.43976203, -0.32445842, 0.08919123, -0.6732706, 0.003777869, 0.56608033, 0.9314576, -0.13060005, -0.088135466, -0.108308144, 0.27884117, -0.46055293, 0.07342696, 0.0559225, 0.69816613, 0.4011239, -0.028544694, 0.08064641, 0.026036564, -0.19206068, -0.41460633, -0.4037335, 0.2626454, -0.12135888, 0.3745098, -0.13898301, 0.054465998, -0.116109446, 0.11705433, 0.4324808, -0.12951922, 0.22345495, ...], [-0.07660817, -0.46201295, -0.5043615, -0.37414637, -0.31470814, -0.8197248, -0.44553378, -0.5021222, -0.2418622, -0.031998783, -0.23411427, -0.55792576, 0.64886415, -0.70458436, -0.76247084, 0.19106038, 0.41632313, 0.26451474, -0.6341871, -0.67780197, 0.07453282, -0.50505286, -0.2803194, -0.08616192, 0.52132565, 0.36279613, 0.06505542, 0.8476284, 0.5180436, -0.052286968, 1.2920185, 0.014844066, 0.4599209, 0.7517877, -0.2820122, -0.13168254, 0.8589992, -0.9272397, -0.062209684, 0.22712871, -0.05800619, -0.94080347, 1.1490519, -0.070918664, 0.4371037, 0.16446914, -0.8361203, 0.871916, 0.2964518, -0.35617283, -0.12215503, 0.37325692, -0.031303022, -0.11569968, -0.93556637, -0.35087806, 0.4073037, -0.37156284, 0.17356054, -0.02665485, 0.7202497, 1.1636028, -1.4689933, 0.16169229, 0.5691571, 0.39378658, 1.2258487, -0.65096074, -0.007456261, -0.08383923, 0.19063438, -0.20051263, -0.54743105, -0.023379356, 0.9503865, -0.4447622, 0.17243233, 0.30253276, 0.042590097, 0.07329144, 0.17095493, 0.3200955, -0.2536034, 0.06708895, -0.5525636, -0.22286516, -0.2790356, -0.37580344, 0.0032717872, -0.3346582, -0.7029885, 0.49254662, 0.25746125, 0.0010136539, -0.70784163, 0.6414307, -0.046651535, 0.5646374, -1.0406041, -0.37364417, ...]]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake_bi['word_vec'] = bigram_vect2\n",
    "shake_bi.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242601, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake_bi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5970"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_title_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236631, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake_bi.drop(index=loss_title_token, inplace=True)\n",
    "shake_bi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_bi.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data'\n",
    "\n",
    "datapath_shake_bi = os.path.join(datapath, 'shakespearean_bigrams_pos_w2v.csv')\n",
    "shake_bi.to_csv(datapath_shake_bi, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
